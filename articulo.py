import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import scipy.stats as stats
import pingouin as pg
from scipy.stats import shapiro, levene
import warnings

# Ignorar warnings
warnings.filterwarnings("ignore")

# --- 1. CONFIGURACI√ìN DE P√ÅGINA (Debe ir primero) ---
st.set_page_config(
    page_title="Dashboard Sesgos Raciales",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- INYECCI√ìN DE CSS CORREGIDA ---
SIDEBAR_BACKGROUND_COLOR = "#f0f2f6" 
KPI_CARD_BACKGROUND_COLOR = "#e0f2f7" 
KPI_BORDER_COLOR = "#b2ebf2"

st.markdown(f"""
<style>
    /* 1. Aplicar Times New Roman al contenido general, pero de forma segura */
    html, body, p, div, span, li, a, button, input {{
        font-family: "Times New Roman", Times, serif;
        font-size: 16px;
    }}

    /* 2. Asegurar t√≠tulos */
    h1, h2, h3, h4, h5, h6, .stHeading {{
        font-family: "Times New Roman", Times, serif !important;
    }}

    /* 3. SOLUCI√ìN AL BUG: Proteger los iconos de Streamlit */
    /* Forzamos a que los iconos usen su fuente original y no Times New Roman */
    [data-testid="stExpanderToggleIcon"] {{
        font-family: "Material Symbols Rounded", "Material Icons", sans-serif !important;
        font-style: normal !important;
        font-weight: normal !important;
        font-variant: normal !important;
        text-transform: none !important;
        line-height: 1;
        display: inline-block;
        /* Aseguramos que el texto del icono sea visible como icono */
        text-indent: 0px !important; 
    }}
    
    /* Asegurar que el contenido dentro del icono (el SVG o texto) no se oculte */
    [data-testid="stExpanderToggleIcon"] > * {{
        text-indent: 0px !important;
    }}

    /* 4. Estilos de la Barra Lateral */
    [data-testid="stSidebar"] {{ 
        background-color: {SIDEBAR_BACKGROUND_COLOR};
    }}

    /* 5. Estilo para las tarjetas de KPI (Metric Containers) */
    [data-testid="stMetric"] {{
        background-color: {KPI_CARD_BACKGROUND_COLOR};
        border-radius: 10px;
        border: 1px solid {KPI_BORDER_COLOR};
        padding: 15px;
        box-shadow: 2px 2px 8px rgba(0, 0, 0, 0.1);
    }}
    
    /* Centrar etiquetas de m√©tricas */
    [data-testid="stMetricLabel"] {{
        display: flex;
        justify-content: center;
        font-weight: bold;
    }}
    
    /* Centrar valor de m√©tricas */
    [data-testid="stMetricValue"] {{
        display: flex;
        justify-content: center;
    }}

</style>
""", unsafe_allow_html=True)

# Paleta de Colores
COLOR_AZULITO = "#A5D6A7" 
COLOR_ROSITA = "#F8BBD0"
COLOR_PRIME_BLACK = '#3949AB' 
COLOR_PRIME_WHITE = '#E91E63'


@st.cache_data
def load_data(file_name):
    """Funci√≥n para cargar y cachear datos."""
    try:
        df = pd.read_csv(file_name)
        # Convertir a categ√≥rico
        if 'id' in df.columns:
            df['id'] = df['id'].astype('category')
        if 'prime' in df.columns:
            df['prime'] = df['prime'].astype('category')
        if 'target' in df.columns:
            df['target'] = df['target'].astype('category')
        return df
    except FileNotFoundError:
        st.error(f"Error: Archivo '{file_name}' no encontrado. Aseg√∫rate de que los archivos CSV est√©n en la carpeta correcta.")
        return pd.DataFrame()

def formatear_tabla_anova(anova_df):
    """
    Formatea la salida de Pingouin para que coincida con la tabla estilo Minitab/SAS:
    Source | DF | Adj SS | Adj MS | F-Value | P-Value
    """
    # 1. Mapeo de nombres de columnas de Pingouin a tu formato deseado
    nombres_nuevos = {
        'Source': 'Source',
        'DF': 'DF',      # Pingouin ya devuelve 'DF' cuando detailed=True
        'SS': 'Adj SS',  # Sum of Squares -> Adj SS
        'MS': 'Adj MS',  # Mean Square -> Adj MS
        'F': 'F-Value',
        'p-unc': 'P-Value'
    }
    
    # 2. Seleccionar solo las columnas que existen en el mapeo
    # (Filtramos np2 o eps que no est√°n en tu imagen)
    cols_a_mantener = [col for col in nombres_nuevos.keys() if col in anova_df.columns]
    df_final = anova_df[cols_a_mantener].rename(columns=nombres_nuevos)
    
    # 3. Redondeo para est√©tica (opcional, puedes ajustar los decimales)
    # P-Value suele requerir m√°s precisi√≥n, el resto 2 o 3 decimales.
    return df_final

# Carga de todos los dataframes
data_raw = load_data("ANOVA beh RT.csv")
data_mvpa = load_data("ANOVA object-sensitive_WIT.csv")
data_search = load_data("ANOVA searchlight_WIT.csv")

# --- 2. PRE-PROCESAMIENTO Y FILTRADO (Manteniendo la l√≥gica original) ---

if not data_raw.empty:
    data_limpia = data_raw.copy()
    
    # Filtrado de Outliers Conductuales
    data_limpia_filtrada = data_limpia[
        (data_limpia['rt_raw'] > 200) & (data_limpia['rt_raw'] < 2000)
    ].copy()
    
    # Si los datos neuro est√°n presentes, aplicar l√≥gica de limpieza original (conversi√≥n de 'value')
    def clean_neuro_data(df):
        if not df.empty and 'value' in df.columns:
            data = df.copy()
            data['value'] = (data['value'].astype(str)
                             .str.replace(r'\s+', '', regex=True)
                             .str.replace(r'\.(?=.*\.)', '', regex=True)
                             .astype(float))
            # Asegurar factores
            data['id'] = data['id'].astype('category')
            data['prime'] = data['prime'].astype('category')
            data['target'] = data['target'].astype('category')
            return data
        return df

    data_limpiamvpa = clean_neuro_data(data_mvpa)
    data_limpiasearch = clean_neuro_data(data_search)
else:
    st.stop() # Detener si no hay datos principales

# --- 3. BARRA LATERAL ---
with st.sidebar:
    st.title("Reporte Anal√≠tico")
    st.header("Estudio: Sesgos Raciales")
    st.markdown("**Autores:**")
    st.markdown(" - Juan David Roa")
    st.markdown(" - Laura Camila Rodr√≠guez G.")
    st.markdown("---")
    st.caption(f"√öltima Actualizaci√≥n: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}")

# --- 4. T√çTULO PRINCIPAL Y TABS ---
st.markdown("# Sesgos Raciales en la Percepci√≥n de Objetos")
st.markdown("## Juan David Roa - Laura Camila Rodr√≠guez G.")

# ==============================================================================
# === SECCI√ìN KPI ACTUALIZADA ===
# ==============================================================================
st.markdown("---")
st.subheader("üéØ Indicadores Clave de Desempe√±o (KPIs) Conductuales")

# Calcular m√©tricas importantes
total_participantes = data_limpia['id'].nunique()
media_rt_general = data_limpia['rt_raw'].mean()
media_rt_log_general = data_limpia['rt_log'].mean()
desviacion_estandar_rt = data_limpia['rt_raw'].std()

# Crear columnas para las m√©tricas
col_p, col_rt_mean, col_rt_log_mean, col_rt_std = st.columns(4)

with col_p:
    st.metric(label="üë• Total Participantes", value=f"{total_participantes}")
with col_rt_mean:
    st.metric(label="‚è±Ô∏è Media Global RT (ms)", value=f"{media_rt_general:.2f}", help="Tiempo de Reacci√≥n Bruto Promedio.")
with col_rt_log_mean:
    st.metric(label="üìà Media Global RT (log)", value=f"{media_rt_log_general:.2f}", help="Tiempo de Reacci√≥n Promedio (Transformaci√≥n Logar√≠tmica).")
with col_rt_std:
    st.metric(label="üìè Desviaci√≥n Est√°ndar RT (ms)", value=f"{desviacion_estandar_rt:.2f}", help="Variabilidad en los Tiempos de Reacci√≥n Brutos.")

st.markdown("---")
# ==============================================================================
# === FIN DE LA SECCI√ìN KPI ===
# ==============================================================================

tab_intro, tab_viz, tab_anova_beh, tab_anova_mvpa, tab_anova_search = st.tabs([
    "üìù Introducci√≥n y Exploraci√≥n", 
    "üìà Visualizaci√≥n de Interacci√≥n", 
    "üìä ANOVA Conductual (RT)", 
    "üß† ANOVA MVPA (Sensitive WIT)",
    "üîç ANOVA Searchlight (WIT)"
])

# ==============================================================================
# === TAB 1: INTRODUCCI√ìN Y EXPLORACI√ìN ===
# ==============================================================================
with tab_intro:
    st.header("Introducci√≥n y Contexto Experimental")
    st.write(
        "Este informe presenta un an√°lisis exploratorio de datos (EDA) " 
        "basado en un estudio experimental que eval√∫a la presencia de sesgo "
        "racial impl√≠cito en la identificaci√≥n r√°pida de objetos. " 
        "Espec√≠ficamente, se examina si los participantes muestran "
        "diferencias en sus tiempos de reacci√≥n al identificar armas (*guns*) versus "
        "herramientas (*tools*) cuando se les presenta previamente una cara de una "
        "persona negra (*Black prime*) o blanca (*White prime*). El objetivo es explorar "
        "si existe una interacci√≥n entre el tipo de *prime* racial y el tipo de objeto, "
        "lo cual ser√≠a indicativo de un sesgo estereotipado (por ejemplo, asociar m√°s "
        "r√°pidamente armas con personas negras)."
    )
    
    st.markdown("---")
    
    st.header("Datos y Balance del Dise√±o")
    
    # Resumen Estad√≠stico
    st.markdown("### Resumen Estad√≠stico")
    st.dataframe(data_raw.describe().round(2))
    st.markdown("**Comentario**: Se verifican las variables y la ausencia de valores faltantes. El conjunto de datos contiene las columnas `prime`, `target`, `rt_raw` y `rt_log`, listas para el an√°lisis.")
    
    # Balance
    st.markdown("### Balance del Dise√±o")
    tabla = pd.crosstab(data_limpia['prime'], data_limpia['target'])
    st.dataframe(tabla)
    st.markdown("**Comentario**: El dise√±o est√° balanceado: cada combinaci√≥n de `prime` y `target` tiene el mismo n√∫mero de observaciones, lo cual es necesario para un an√°lisis de varianza v√°lido.")
    
    st.markdown("---")
    
    st.header("Distribuci√≥n de los Tiempos de Reacci√≥n (RT)")
    
    # --- Distribuci√≥n Datos Brutos y Transformados ---
    col_raw_dist, col_log_dist = st.columns(2)

    with col_raw_dist:
        st.subheader("Datos Brutos ($RT_{raw}$)")
        # Gr√°ficos de Datos Brutos con Plotly
        
        # Histograma
        fig_hist_raw = px.histogram(
            data_limpia, 
            x='rt_raw', 
            nbins=30,
            title='Histograma: Datos Brutos',
            labels={'rt_raw': 'Tiempo de reacci√≥n (ms)'},
            color_discrete_sequence=[COLOR_AZULITO]
        )
        fig_hist_raw.update_traces(marker_line_color='black', marker_line_width=1)
        fig_hist_raw.update_layout(
            title_font_size=14,
            title_font_family="Times New Roman",
            font_family="Times New Roman",
            template='plotly_white',
            height=300
        )
        st.plotly_chart(fig_hist_raw, use_container_width=True, key="hist_raw")
        
        # Q-Q Plot
        qq_data = stats.probplot(data_limpia['rt_raw'], dist="norm")
        fig_qq_raw = go.Figure()
        fig_qq_raw.add_trace(go.Scatter(
            x=qq_data[0][0],
            y=qq_data[0][1],
            mode='markers',
            marker=dict(color=COLOR_AZULITO, size=6),
            name='Datos'
        ))
        # L√≠nea te√≥rica
        fig_qq_raw.add_trace(go.Scatter(
            x=qq_data[0][0],
            y=qq_data[1][0] * qq_data[0][0] + qq_data[1][1],
            mode='lines',
            line=dict(color='black', width=2),
            name='Te√≥rica'
        ))
        fig_qq_raw.update_layout(
            title='Q-Q Plot: Datos Brutos',
            title_font_size=14,
            title_font_family="Times New Roman",
            font_family="Times New Roman",
            xaxis_title='Cuantiles te√≥ricos',
            yaxis_title='Cuantiles muestrales',
            template='plotly_white',
            showlegend=False,
            height=300
        )
        st.plotly_chart(fig_qq_raw, use_container_width=True, key="qq_raw")
        st.markdown("**Comentario**: Los tiempos de reacci√≥n brutos muestran una fuerte asimetr√≠a positiva, lo que viola el supuesto de normalidad. Se justifica la transformaci√≥n logar√≠tmica.")

    with col_log_dist:
        st.subheader("Datos Transformados ($RT_{log}$)")
        # Gr√°ficos de Datos Transformados con Plotly
        
        # Histograma
        fig_hist_log = px.histogram(
            data_limpia, 
            x='rt_log', 
            nbins=30,
            title='Histograma: Datos Transformados',
            labels={'rt_log': 'log(Tiempo de reacci√≥n)'},
            color_discrete_sequence=[COLOR_ROSITA]
        )
        fig_hist_log.update_traces(marker_line_color='black', marker_line_width=1)
        fig_hist_log.update_layout(
            title_font_size=14,
            title_font_family="Times New Roman",
            font_family="Times New Roman",
            template='plotly_white',
            height=300
        )
        st.plotly_chart(fig_hist_log, use_container_width=True, key="hist_log")
        
        # Q-Q Plot
        qq_data = stats.probplot(data_limpia['rt_log'], dist="norm")
        fig_qq_log = go.Figure()
        fig_qq_log.add_trace(go.Scatter(
            x=qq_data[0][0],
            y=qq_data[0][1],
            mode='markers',
            marker=dict(color=COLOR_ROSITA, size=6),
            name='Datos'
        ))
        # L√≠nea te√≥rica
        fig_qq_log.add_trace(go.Scatter(
            x=qq_data[0][0],
            y=qq_data[1][0] * qq_data[0][0] + qq_data[1][1],
            mode='lines',
            line=dict(color='black', width=2),
            name='Te√≥rica'
        ))
        fig_qq_log.update_layout(
            title='Q-Q Plot: Datos Transformados',
            title_font_size=14,
            title_font_family="Times New Roman",
            font_family="Times New Roman",
            xaxis_title='Cuantiles te√≥ricos',
            yaxis_title='Cuantiles muestrales',
            template='plotly_white',
            showlegend=False,
            height=300
        )
        st.plotly_chart(fig_qq_log, use_container_width=True, key="qq_log")
        st.markdown("**Comentario**: La transformaci√≥n logar√≠tmica mejora significativamente la normalidad de los datos, haciendo que la distribuci√≥n se aproxime m√°s a una normal. Es adecuada para an√°lisis param√©tricos posteriores.")

# ==============================================================================
# === TAB 2: VISUALIZACI√ìN DE INTERACCI√ìN (Mann-Whitney ELIMINADO) ===
# ==============================================================================
with tab_viz:
    st.header("Visualizaci√≥n Detallada de la Interacci√≥n Esperada")

    # --- Boxplot y Estad√≠sticas ---
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("Diagrama de Cajas de Tiempo de Respuesta (log)")
        # Generaci√≥n del Boxplot con Plotly
        
        fig_box = px.box(
            data_limpia, 
            x='prime', 
            y='rt_log', 
            color='target',
            color_discrete_map={"gun": COLOR_PRIME_BLACK, "tool": COLOR_PRIME_WHITE},
            title='Diagrama de cajas de tiempo de respuesta (log)',
            labels={
                'prime': 'Raza del prime',
                'rt_log': 'Tiempo de respuesta (log)',
                'target': 'Target'
            },
            points='all',  # Muestra todos los puntos
            category_orders={'target': ['gun', 'tool']}
        )
        
        fig_box.update_traces(
            marker=dict(size=3, opacity=0.5),
            boxmean=True
        )
        
        fig_box.update_layout(
            title_font_size=16,
            title_font_family="Times New Roman",
            font_family="Times New Roman",
            template='plotly_white',
            height=600,
            legend=dict(
                title='Target',
                yanchor='top',
                y=0.99,
                xanchor='right',
                x=0.99,
                bgcolor='rgba(255,255,255,0.9)'
            ),
            xaxis=dict(title_font_size=14),
            yaxis=dict(title_font_size=14, gridcolor='rgba(0,0,0,0.1)')
        )
        
        # Actualizar nombres en leyenda
        fig_box.for_each_trace(lambda t: t.update(name='Arma' if t.name == 'gun' else 'Herramienta'))
        
        st.plotly_chart(fig_box, use_container_width=True, key="boxplot_main")

        # INTERPRETACI√ìN MOVIDA AQU√ç (Bajo el Boxplot)
        st.markdown(
            "> **Interpretaci√≥n de Medidas Descriptivas**:\n"
            "- Los tiempos de reacci√≥n son m√°s bajos (m√°s r√°pidos) para armas que para herramientas.\n"
            "- La diferencia entre armas y herramientas parece ser mayor cuando el *prime* es **Black**.\n"
            "- Para armas, los tiempos de reacci√≥n son similares independientemente del prime racial.\n"
            "Este patr√≥n gr√°fico sugiere la **interacci√≥n clave** (sesgo racial impl√≠cito) que ser√° confirmada por el ANOVA."
        )

    with col2:
        st.subheader("Estad√≠sticas por Grupo")
        stats_df = data_limpia.groupby(['prime', 'target'])['rt_log'].agg([
            'count', 'mean', 'std', 'median'
        ]).round(3)
        st.dataframe(stats_df, use_container_width=True)
        
        st.subheader("Tests de Inferencia Univariados")
        st.info("Los tests inferenciales de comparaci√≥n (e.g., Mann-Whitney) se han omitido en esta secci√≥n para enfocarse en la visualizaci√≥n descriptiva. El **ANOVA** confirma la interacci√≥n en la siguiente pesta√±a.")

    st.markdown("---")
    
    st.header("Gr√°fico de Interacci√≥n - Prime vs Target")
    
    # Calcular medias y errores est√°ndar para el gr√°fico de interacci√≥n
    interaction_data = data_limpia.groupby(['target', 'prime'])['rt_log'].agg(['mean', 'sem']).reset_index()
    
    fig_interaction = go.Figure()
    
    for prime_val, color, symbol in zip(
        ['Black', 'White'], 
        [COLOR_PRIME_BLACK, COLOR_PRIME_WHITE],
        ['circle', 'square']
    ):
        subset = interaction_data[interaction_data['prime'] == prime_val]
        
        fig_interaction.add_trace(go.Scatter(
            x=subset['target'],
            y=subset['mean'],
            error_y=dict(type='data', array=subset['sem'], visible=True, width=4, thickness=2),
            mode='lines+markers',
            name=prime_val,
            line=dict(color=color, width=2),
            marker=dict(size=12, color=color, symbol=symbol, line=dict(color='white', width=1)),
            text=[f"{val:.2f}" for val in subset['mean']],
            textposition='top center',
            textfont=dict(size=10, family="Times New Roman", color='black'),
            showlegend=True
        ))
        
        # A√±adir anotaciones con valores
        for idx, row in subset.iterrows():
            fig_interaction.add_annotation(
                x=row['target'],
                y=row['mean'] + 0.03,
                text=f"{row['mean']:.2f}",
                showarrow=False,
                font=dict(size=10, family="Times New Roman", color='black'),
                bgcolor='white',
                borderpad=2,
                opacity=0.8
            )
    
    fig_interaction.update_layout(
        title='Interacci√≥n entre Prime y Target en TR (log)',
        title_font_size=18,
        title_font_family="Times New Roman",
        font_family="Times New Roman",
        xaxis_title='Target',
        yaxis_title='Tiempo de respuesta (log)',
        xaxis=dict(title_font_size=14),
        yaxis=dict(title_font_size=14, gridcolor='rgba(0,0,0,0.1)'),
        template='plotly_white',
        height=500,
        legend=dict(
            title='Raza',
            yanchor='top',
            y=0.99,
            xanchor='right',
            x=0.99,
            bgcolor='rgba(255,255,255,0.9)',
            font=dict(size=12)
        ),
        hovermode='closest'
    )
    
    st.plotly_chart(fig_interaction, use_container_width=True, key="interaction_plot")
    
    st.markdown(
        "**Comentario**: Este gr√°fico muestra claramente la no-paralelidad, indicando una interacci√≥n significativa entre prime y target: la l√≠nea para el prime Black (**Azul**) muestra una mayor separaci√≥n entre herramientas y armas, mientras que la del prime White (**Rosa**) es m√°s plana. Este patr√≥n refleja que los participantes responden m√°s lentamente a herramientas tras un prime Black, pero su velocidad para identificar armas no var√≠a significativamente seg√∫n el prime ‚Äî evidencia conductual del sesgo racial impl√≠cito."
    )

# ==============================================================================
# === TAB 3: ANOVA CONDUCTUAL (RT) ===
# ==============================================================================
with tab_anova_beh:
    st.header("üìä ANOVA de Medidas Repetidas: Tiempos de Reacci√≥n ($RT_{log}$)")
    
    # --- CAMBIO 1: detailed=True para obtener SS y MS ---
    anova_rt = pg.rm_anova(
        data=data_limpia, 
        dv='rt_log', 
        within=['prime', 'target'], 
        subject='id', 
        detailed=True  # <--- IMPORTANTE: Esto genera las columnas SS, MS y DF
    )
    
    # --- CAMBIO 2: Formatear usando la funci√≥n auxiliar ---
    tabla_final = formatear_tabla_anova(anova_rt)
    
    # Mostrar tabla
    st.subheader("Resultados ANOVA: Conductual")
    st.dataframe(
        tabla_final.style.format({
            'Adj SS': '{:.3f}',
            'Adj MS': '{:.3f}',
            'F-Value': '{:.3f}',
            'P-Value': '{:.4f}'
        }),
        hide_index=True,
        use_container_width=True
    )
    
    # L√≥gica de interpretaci√≥n (puedes mantener tu l√≥gica de significancia visual si quieres)
    p_interaction = anova_rt.loc[anova_rt['Source'] == 'prime * target', 'p-unc'].values[0]
    
    if p_interaction < 0.05:
        st.success(f"‚úÖ Se confirma una interacci√≥n significativa (p = {p_interaction:.4f}).")
    else:
        st.info(f"‚ÑπÔ∏è No se encontr√≥ interacci√≥n significativa (p = {p_interaction:.4f}).")

    
    st.markdown(
        "**Interpretaci√≥n**: Se confirma una **interacci√≥n significativa** entre prime y target (p < .05), "
        "respaldando la hip√≥tesis de sesgo racial impl√≠cito. El efecto principal de target es muy fuerte (p < .001), "
        "mientras que no hay efecto significativo de prime por s√≠ solo."
    )
    
    st.markdown("---")
    
    with st.expander("üîç Ver An√°lisis de Supuestos (Residuos)", expanded=False):
        st.markdown("### Verificaci√≥n de Supuestos del Modelo")
        
        # C√ÅLCULO DE RESIDUOS 
        y_bar_total = data_limpia['rt_log'].mean()
        mean_sujeto = data_limpia.groupby('id')['rt_log'].mean().reset_index().rename(columns={'rt_log': 'y_bar_sujeto'})
        mean_celda = data_limpia.groupby(['prime', 'target'])['rt_log'].mean().reset_index().rename(columns={'rt_log': 'y_bar_celda'})
        
        data_resid = data_limpia.merge(mean_sujeto, on='id').merge(mean_celda, on=['prime', 'target'])
        data_resid['residual'] = data_resid['rt_log'] - data_resid['y_bar_celda'] - data_resid['y_bar_sujeto'] + y_bar_total
        residuos = data_resid['residual']
        
        col_test, col_qq = st.columns([1, 2])
        
        with col_test:
            st.markdown("#### Pruebas Estad√≠sticas")
            # Shapiro-Wilk
            shapiro_stat, shapiro_p = shapiro(residuos)
            st.metric("Normalidad (Shapiro-Wilk)", f"p = {shapiro_p:.4f}")
            # Levene
            grupos = [grupo['residual'].values for _, grupo in data_resid.groupby(['prime', 'target'])]
            levene_stat, levene_p = levene(*grupos)
            st.metric("Homogeneidad (Levene)", f"p = {levene_p:.4f}")
            
            # Interpretaci√≥n autom√°tica
            st.markdown("---")
            normalidad_ok = shapiro_p > 0.05
            homogeneidad_ok = levene_p > 0.05
            
            if normalidad_ok and homogeneidad_ok:
                st.success("‚úì Los supuestos se cumplen adecuadamente")
            elif normalidad_ok:
                st.warning("‚ö†Ô∏è Normalidad OK, pero revisar homogeneidad")
            elif homogeneidad_ok:
                st.warning("‚ö†Ô∏è Homogeneidad OK, pero revisar normalidad")
            else:
                st.info("‚ÑπÔ∏è Considerar transformaciones adicionales")
        
        with col_qq:
            st.markdown("#### Q-Q Plot de Residuos")
            # Q-Q Plot Residuos con Plotly
            qq_data = stats.probplot(residuos, dist="norm")
            fig_qq = go.Figure()
            fig_qq.add_trace(go.Scatter(
                x=qq_data[0][0],
                y=qq_data[0][1],
                mode='markers',
                marker=dict(color=COLOR_AZULITO, size=6),
                name='Residuos'
            ))
            # L√≠nea te√≥rica
            fig_qq.add_trace(go.Scatter(
                x=qq_data[0][0],
                y=qq_data[1][0] * qq_data[0][0] + qq_data[1][1],
                mode='lines',
                line=dict(color='black', width=2),
                name='Te√≥rica'
            ))
            fig_qq.update_layout(
                title='',
                title_font_family="Times New Roman",
                font_family="Times New Roman",
                xaxis_title='Cuantiles te√≥ricos',
                yaxis_title='Cuantiles muestrales',
                template='plotly_white',
                showlegend=False,
                height=350
            )
            st.plotly_chart(fig_qq, use_container_width=True, key="qq_residuos_beh")

# ==============================================================================
# === TAB 4: ANOVA MVPA (Sensitive WIT) ===
# ==============================================================================
with tab_anova_mvpa:
    st.header("üß† ANOVA de Medidas Repetidas: MVPA - Sensitive WIT")
    
    if not data_limpiamvpa.empty:
        # --- CAMBIO 1 ---
        anova_mvpa = pg.rm_anova(
            data=data_limpiamvpa, 
            dv='value', 
            within=['prime', 'target'], 
            subject='id', 
            detailed=True # <--- Activado
        )
        
        # --- CAMBIO 2 ---
        tabla_final_mvpa = formatear_tabla_anova(anova_mvpa)
        
        st.subheader("Resultados ANOVA: MVPA")
        st.dataframe(
            tabla_final_mvpa.style.format({
                'Adj SS': '{:.3f}',
                'Adj MS': '{:.3f}',
                'F-Value': '{:.3f}',
                'P-Value': '{:.4f}'
            }),
            hide_index=True,
            use_container_width=True
        )
        
        st.markdown("---")
        
        with st.expander("üîç Ver An√°lisis de Supuestos (Residuos)", expanded=False):
            st.markdown("### Verificaci√≥n de Supuestos del Modelo")
            
            # C√ÅLCULO DE RESIDUOS 
            y_bar_total_mvpa = data_limpiamvpa['value'].mean()
            mean_sujeto_mvpa = data_limpiamvpa.groupby('id')['value'].mean().reset_index().rename(columns={'value': 'y_bar_sujeto_mvpa'})
            mean_celda_mvpa = data_limpiamvpa.groupby(['prime', 'target'])['value'].mean().reset_index().rename(columns={'value': 'y_bar_celda_mvpa'})
            
            data_resid_mvpa = (data_limpiamvpa
                                .merge(mean_sujeto_mvpa, on='id')
                                .merge(mean_celda_mvpa, on=['prime', 'target']))
            
            data_resid_mvpa['residual_mvpa'] = (data_resid_mvpa['value'] - 
                                                data_resid_mvpa['y_bar_celda_mvpa'] - 
                                                data_resid_mvpa['y_bar_sujeto_mvpa'] + 
                                                y_bar_total_mvpa)
            residuos_mvpa = data_resid_mvpa['residual_mvpa']
            
            col_test_mvpa, col_qq_mvpa = st.columns([1, 2])
            
            with col_test_mvpa:
                st.markdown("#### Pruebas Estad√≠sticas")
                # Shapiro-Wilk
                shapiro_stat, shapiro_p = shapiro(residuos_mvpa)
                st.metric("Normalidad (Shapiro-Wilk)", f"p = {shapiro_p:.4f}")
                # Levene
                grupos = [grupo['residual_mvpa'].values for _, grupo in data_resid_mvpa.groupby(['prime', 'target'])]
                levene_stat, levene_p = levene(*grupos)
                st.metric("Homogeneidad (Levene)", f"p = {levene_p:.4f}")
                
                # Interpretaci√≥n autom√°tica
                st.markdown("---")
                normalidad_ok = shapiro_p > 0.05
                homogeneidad_ok = levene_p > 0.05
                
                if normalidad_ok and homogeneidad_ok:
                    st.success("‚úì Los supuestos se cumplen adecuadamente")
                elif normalidad_ok:
                    st.warning("‚ö†Ô∏è Normalidad OK, pero revisar homogeneidad")
                elif homogeneidad_ok:
                    st.warning("‚ö†Ô∏è Homogeneidad OK, pero revisar normalidad")
                else:
                    st.info("‚ÑπÔ∏è Considerar transformaciones adicionales")
            
            with col_qq_mvpa:
                st.markdown("#### Q-Q Plot de Residuos")
                # Q-Q Plot Residuos MVPA con Plotly
                qq_data = stats.probplot(residuos_mvpa, dist="norm")
                fig_qq_mvpa = go.Figure()
                fig_qq_mvpa.add_trace(go.Scatter(
                    x=qq_data[0][0],
                    y=qq_data[0][1],
                    mode='markers',
                    marker=dict(color=COLOR_PRIME_BLACK, size=6),
                    name='Residuos'
                ))
                # L√≠nea te√≥rica
                fig_qq_mvpa.add_trace(go.Scatter(
                    x=qq_data[0][0],
                    y=qq_data[1][0] * qq_data[0][0] + qq_data[1][1],
                    mode='lines',
                    line=dict(color='black', width=2),
                    name='Te√≥rica'
                ))
                fig_qq_mvpa.update_layout(
                    title='',
                    title_font_family="Times New Roman",
                    font_family="Times New Roman",
                    xaxis_title='Cuantiles te√≥ricos',
                    yaxis_title='Cuantiles muestrales',
                    template='plotly_white',
                    showlegend=False,
                    height=350
                )
                st.plotly_chart(fig_qq_mvpa, use_container_width=True, key="qq_residuos_mvpa")
    else:
        st.warning("Datos MVPA no cargados o no disponibles.")

# ==============================================================================
# === TAB 5: ANOVA SEARCHLIGHT (WIT) ===
# ==============================================================================
with tab_anova_search:
    st.header("üîç ANOVA de Medidas Repetidas: Searchlight WIT")
    
    if not data_limpiasearch.empty:
        # C√ÅLCULO ANOVA
        anova_search = pg.rm_anova(
            data=data_limpiasearch, 
            dv='value', 
            within=['prime', 'target'], 
            subject='id',
            detailed=True
        )
        
        # Formatear tabla usando la funci√≥n auxiliar
        tabla_final = formatear_tabla_anova(anova_search)
        
        # Mostrar tabla
        st.subheader("Resultados ANOVA: Searchlight")
        st.dataframe(
            tabla_final.style.format({
                'Adj SS': '{:.3f}',
                'Adj MS': '{:.3f}',
                'F-Value': '{:.3f}',
                'P-Value': '{:.4f}'
            }),
            hide_index=True,
            use_container_width=True
        )
        
        st.markdown("---")
        
        with st.expander("üîç Ver An√°lisis de Supuestos (Residuos)", expanded=False):
            st.markdown("### Verificaci√≥n de Supuestos del Modelo")
            
            # C√ÅLCULO DE RESIDUOS 
            y_bar_total_search = data_limpiasearch['value'].mean()
            mean_sujeto_search = data_limpiasearch.groupby('id')['value'].mean().reset_index().rename(columns={'value': 'y_bar_sujeto_search'})
            mean_celda_search = data_limpiasearch.groupby(['prime', 'target'])['value'].mean().reset_index().rename(columns={'value': 'y_bar_celda_search'})
            
            data_resid_search = (data_limpiasearch
                                .merge(mean_sujeto_search, on='id')
                                .merge(mean_celda_search, on=['prime', 'target']))
            
            data_resid_search['residual_search'] = (data_resid_search['value'] - 
                                                    data_resid_search['y_bar_celda_search'] - 
                                                    data_resid_search['y_bar_sujeto_search'] + 
                                                    y_bar_total_search)
            residuos_search = data_resid_search['residual_search']
            
            col_test_search, col_qq_search = st.columns([1, 2])
            
            with col_test_search:
                st.markdown("#### Pruebas Estad√≠sticas")
                # Shapiro-Wilk
                shapiro_stat, shapiro_p = shapiro(residuos_search)
                st.metric("Normalidad (Shapiro-Wilk)", f"p = {shapiro_p:.4f}")
                # Levene
                grupos = [grupo['residual_search'].values for _, grupo in data_resid_search.groupby(['prime', 'target'])]
                levene_stat, levene_p = levene(*grupos)
                st.metric("Homogeneidad (Levene)", f"p = {levene_p:.4f}")
                
                # Interpretaci√≥n autom√°tica
                st.markdown("---")
                normalidad_ok = shapiro_p > 0.05
                homogeneidad_ok = levene_p > 0.05
                
                if normalidad_ok and homogeneidad_ok:
                    st.success("‚úì Los supuestos se cumplen adecuadamente")
                elif normalidad_ok:
                    st.warning("‚ö†Ô∏è Normalidad OK, pero revisar homogeneidad")
                elif homogeneidad_ok:
                    st.warning("‚ö†Ô∏è Homogeneidad OK, pero revisar normalidad")
                else:
                    st.info("‚ÑπÔ∏è Considerar transformaciones adicionales")
            
            with col_qq_search:
                st.markdown("#### Q-Q Plot de Residuos")
                # Q-Q Plot Residuos Searchlight con Plotly
                qq_data = stats.probplot(residuos_search, dist="norm")
                fig_qq_search = go.Figure()
                fig_qq_search.add_trace(go.Scatter(
                    x=qq_data[0][0],
                    y=qq_data[0][1],
                    mode='markers',
                    marker=dict(color=COLOR_PRIME_WHITE, size=6),
                    name='Residuos'
                ))
                # L√≠nea te√≥rica
                fig_qq_search.add_trace(go.Scatter(
                    x=qq_data[0][0],
                    y=qq_data[1][0] * qq_data[0][0] + qq_data[1][1],
                    mode='lines',
                    line=dict(color='black', width=2),
                    name='Te√≥rica'
                ))
                fig_qq_search.update_layout(
                    title='',
                    title_font_family="Times New Roman",
                    font_family="Times New Roman",
                    xaxis_title='Cuantiles te√≥ricos',
                    yaxis_title='Cuantiles muestrales',
                    template='plotly_white',
                    showlegend=False,
                    height=350
                )
                st.plotly_chart(fig_qq_search, use_container_width=True, key="qq_residuos_search")
    else:
        st.warning("Datos Searchlight no cargados o no disponibles.")
